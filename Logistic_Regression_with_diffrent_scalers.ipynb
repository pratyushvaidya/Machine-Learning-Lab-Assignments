{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression with diffrent scalers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMZH5kUAk3fUzBVU02FWZ2V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratyushvaidya/Machine-Learning-Lab-Assignments/blob/master/Logistic_Regression_with_diffrent_scalers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04IXTKhm0yf0",
        "colab_type": "text"
      },
      "source": [
        "###Logistic Regression (1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmF_gQpD02c1",
        "colab_type": "text"
      },
      "source": [
        "Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CqUTilt0yCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSc8h9OR24o9",
        "colab_type": "text"
      },
      "source": [
        "Normalization : Min-Max Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf3MIEew29BX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(X):\n",
        "  mins = np.min(X, axis=0)\n",
        "  maxs = np.max(X,axis=0)\n",
        "\n",
        "  diff = maxs-mins\n",
        "  print(mins,maxs)\n",
        "  return 1-((maxs-X)/diff)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fndvt00b-WoK",
        "colab_type": "text"
      },
      "source": [
        "Pre-Activation and Activation Calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhrLw237-dzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(X,theta):\n",
        "  return 1.0/(1 + np.exp(-np.dot(X, theta.T)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7Xh5n7Y9pWA",
        "colab_type": "text"
      },
      "source": [
        "Cost Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSi3UcEp6Big",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cf(X,Y,theta):\n",
        "  # COST = Y*log(h(X)) - (1-Y)*log(1-h(X))\n",
        "  cost = Y*np.log(sigmoid(X,theta)) - (1-Y)*np.log(1-sigmoid(X,theta))\n",
        "  return np.mean(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t13--eP99wdp",
        "colab_type": "text"
      },
      "source": [
        "Calculating Derivative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbG5fMbZ9zm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def derivative(X, Y, theta):\n",
        "  # DERIVATIVE = [Y(PREDICTION) - Y(ACTUAL)].TRANSPOSE * X\n",
        "  return np.dot((sigmoid(X,theta) - Y.reshape(X.shape[0], -1)).T,X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oIv5CGu5Rnt",
        "colab_type": "text"
      },
      "source": [
        "Gradient Descent Algorihm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL3YOCcX5ytn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient_descent(X,Y,theta,lr=0.01,conv=.001):\n",
        "  cost = cf(X,Y,theta)\n",
        "  change = 1\n",
        "  epochs = 1\n",
        "  while(change>conv):\n",
        "    old_cost = cost\n",
        "    theta = theta - lr*derivative(X,Y,theta)\n",
        "    cost = cf(X,Y,theta)\n",
        "    change = old_cost-cost\n",
        "    epochs+=1\n",
        "  return theta, epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-orznYL8f0c",
        "colab_type": "text"
      },
      "source": [
        "Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n83PvfKe8MUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(X,theta):\n",
        "  Y_pred = sigmoid(X,theta)\n",
        "  Y_pred = np.where(Y_pred>0.5, 1, 0)\n",
        "  return np.squeeze(Y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P732s93g9hrL",
        "colab_type": "text"
      },
      "source": [
        "Main Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXCe1EIh3VPw",
        "colab_type": "code",
        "outputId": "347ae310-36ef-4adf-f432-1272520441c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  data = np.array(pd.read_csv(\"dataset1.csv\"))\n",
        "\n",
        "  X = data[:,:2]\n",
        "  Y = data[:,2]\n",
        "  #Normalizing the dataset : converting it's value between 0 and 1\n",
        "  X = normalize(X)\n",
        "  #horizontal stacking of ones in the X for bias\n",
        "  X = np.hstack((np.matrix(np.ones(X.shape[0])).T,X))\n",
        "  \n",
        "  theta = np.matrix(np.zeros(X.shape[1]))\n",
        "\n",
        "  theta, epochs = gradient_descent(X, Y, theta)\n",
        "\n",
        "  Y_predicted = predict(X,theta)\n",
        "  print(theta, epochs)\n",
        "  print(\"Correctly predicted: \", np.sum(Y==Y_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.9008 1.169 ] [8.9221 8.5676]\n",
            "[[0.19242517 0.05065823]\n",
            " [0.41640382 0.09866732]\n",
            " [0.6119831  0.17599276]\n",
            " [0.69084812 0.29600195]\n",
            " [0.6119831  0.27999892]\n",
            " [0.68453991 0.35733787]\n",
            " [0.74448032 0.44266483]\n",
            " [0.73501801 0.33867218]\n",
            " [0.90536447 0.4826724 ]\n",
            " [0.81071647 0.36800205]\n",
            " [0.83911585 0.4640067 ]\n",
            " [0.85488637 0.61599492]\n",
            " [0.70661863 0.51200227]\n",
            " [0.55520926 0.3813289 ]\n",
            " [0.44479074 0.25066905]\n",
            " [0.25867378 0.11999567]\n",
            " [0.19242517 0.01332685]\n",
            " [0.         0.        ]\n",
            " [0.15142184 0.07732544]\n",
            " [0.29653547 0.02932987]\n",
            " [0.40694152 0.05333441]\n",
            " [0.49211474 0.09600465]\n",
            " [0.30284368 0.21866299]\n",
            " [0.52996397 0.32266915]\n",
            " [0.6687694  0.3920066 ]\n",
            " [0.6687694  0.43466331]\n",
            " [0.78548365 0.05065823]\n",
            " [0.84226996 0.16800476]\n",
            " [0.65299889 0.08266429]\n",
            " [0.44794485 0.03199254]\n",
            " [0.49526885 0.19467196]\n",
            " [0.57728797 0.25867056]\n",
            " [0.63721591 0.37332739]\n",
            " [0.77917545 0.48533506]\n",
            " [0.84857816 0.55999784]\n",
            " [0.92428908 0.61333225]\n",
            " [0.9495219  0.53333063]\n",
            " [0.97790882 0.5733382 ]\n",
            " [0.86750277 0.35733787]\n",
            " [0.76025083 0.27999892]\n",
            " [0.57413387 0.23466602]\n",
            " [0.50157705 0.20533614]\n",
            " [0.71608093 0.36000054]\n",
            " [0.84542406 0.45600519]\n",
            " [0.88958149 0.62399643]\n",
            " [1.         0.7280026 ]\n",
            " [0.86750277 0.55199632]\n",
            " [0.70977273 0.54933366]\n",
            " [0.64037001 0.48533506]\n",
            " [0.22713276 0.46133052]\n",
            " [0.12934312 0.335996  ]\n",
            " [0.09778964 0.2453302 ]\n",
            " [0.42586613 0.44000216]\n",
            " [0.31546009 0.34933636]\n",
            " [0.57097977 0.55467251]\n",
            " [0.40063331 0.49599924]\n",
            " [0.2870607  0.44000216]\n",
            " [0.40063331 0.57066202]\n",
            " [0.52365577 0.664004  ]\n",
            " [0.49842295 0.59466656]\n",
            " [0.63090771 0.71466223]\n",
            " [0.60567489 0.65333982]\n",
            " [0.72238914 0.75733247]\n",
            " [0.60252079 0.74132944]\n",
            " [0.71292683 0.80800422]\n",
            " [0.78548365 0.85866245]\n",
            " [0.78548365 0.76533398]\n",
            " [0.9589842  0.87200281]\n",
            " [0.85488637 0.81332955]\n",
            " [0.85488637 0.89333117]\n",
            " [0.52365577 0.86934015]\n",
            " [0.41324972 0.72000108]\n",
            " [0.32176829 0.62667261]\n",
            " [0.18296286 0.52000378]\n",
            " [0.11040604 0.40799611]\n",
            " [0.         0.30666613]\n",
            " [0.         0.62399643]\n",
            " [0.13249723 0.69867272]\n",
            " [0.06309451 0.51200227]\n",
            " [0.18927107 0.76799665]\n",
            " [0.24605737 0.664004  ]\n",
            " [0.3880169  0.81066688]\n",
            " [0.47003603 0.8186684 ]\n",
            " [0.53311807 0.94400292]\n",
            " [0.6624612  0.85333712]\n",
            " [0.56782566 0.79466386]\n",
            " [0.63406181 0.99199849]\n",
            " [0.39747921 0.86133863]\n",
            " [0.18611696 0.81600573]\n",
            " [0.0536322  0.72533993]\n",
            " [0.10409784 0.57866353]\n",
            " [0.19242517 0.63199795]\n",
            " [0.2839066  0.50400076]\n",
            " [0.47003603 0.62667261]\n",
            " [0.63406181 0.83733409]\n",
            " [0.47003603 0.68799503]\n",
            " [0.83280765 0.97333279]\n",
            " [0.46686946 1.        ]\n",
            " [0.46686946 0.94593572]]\n",
            "[[ 0.04820514  0.41763595 -0.66015805]] 9\n",
            "Correctly predicted:  95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkjVRDkLiVjD",
        "colab_type": "text"
      },
      "source": [
        "###Logistic Regression using Z-score Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZBLWklfhogo",
        "colab_type": "code",
        "outputId": "1e5b82b6-9a19-40ef-e94f-e21a091ea730",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import csv \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import pandas as pd \n",
        "  \n",
        "def MinMax(X): \n",
        "    ''' \n",
        "    function to normalize feature matrix, X \n",
        "    '''\n",
        "    mins = np.min(X, axis = 0) \n",
        "    maxs = np.max(X, axis = 0) \n",
        "    rng = maxs - mins \n",
        "    norm_X = 1 - ((maxs - X)/rng) \n",
        "    return norm_X \n",
        "  \n",
        "  \n",
        "def ZScore(X):\n",
        "    '''\n",
        "    function to normalize feature matrix, X\n",
        "    '''\n",
        "    diff = X - np.mean(X)\n",
        "    norm_X = diff/np.std(X)\n",
        "    return norm_X\n",
        "\n",
        "\n",
        "def logistic_func(theta, X): \n",
        "    ''' \n",
        "    logistic(sigmoid) function 1/1+e^-theta.T * X\n",
        "    '''\n",
        "    return 1.0/(1 + np.exp(-np.dot(X, theta.T))) \n",
        "  \n",
        "  \n",
        "def log_gradient(theta, X, y): \n",
        "    ''' \n",
        "    logistic gradient function [Y(PREDICTION)- Y(ACTUAL)).Transpose *  X\n",
        "    '''\n",
        "    first_calc = logistic_func(theta, X) - y.reshape(X.shape[0], -1) \n",
        "    final_calc = np.dot(first_calc.T, X) \n",
        "    return final_calc \n",
        "  \n",
        "  \n",
        "def cost_func(theta, X, y): \n",
        "    ''' \n",
        "    cost function, J \n",
        "    '''\n",
        "    log_func_v = logistic_func(theta, X) \n",
        "    y = np.squeeze(y) \n",
        "    step1 = y * np.log(log_func_v) \n",
        "    step2 = (1 - y) * np.log(1 - log_func_v) \n",
        "    final = -step1 - step2 \n",
        "    return np.mean(final) \n",
        "  \n",
        "  \n",
        "def grad_desc(X, y, theta, lr=.01, converge_change=.001): \n",
        "    ''' \n",
        "    gradient descent function \n",
        "    '''\n",
        "    cost = cost_func(theta, X, y) \n",
        "    change_cost = 1\n",
        "    num_iter = 1\n",
        "      \n",
        "    while(change_cost > converge_change): \n",
        "        old_cost = cost \n",
        "        theta = theta - (lr * log_gradient(theta, X, y)) \n",
        "        cost = cost_func(theta, X, y) \n",
        "        change_cost = old_cost - cost \n",
        "        num_iter += 1\n",
        "      \n",
        "    return theta, num_iter  \n",
        "  \n",
        "  \n",
        "def pred_values(theta, X): \n",
        "    ''' \n",
        "    function to predict labels \n",
        "    '''\n",
        "    pred_prob = logistic_func(theta, X) \n",
        "    pred_value = np.where(pred_prob >= .5, 1, 0) \n",
        "    return np.squeeze(pred_value) \n",
        "  \n",
        "  \n",
        "def plot_reg(X, y, theta): \n",
        "    ''' \n",
        "    function to plot decision boundary \n",
        "    '''\n",
        "    # labelled observations \n",
        "    x_0 = X[np.where(y == 0.0)] \n",
        "    x_1 = X[np.where(y == 1.0)] \n",
        "      \n",
        "    # plotting points with diff color for diff label \n",
        "    plt.scatter([x_0[:, 1]], [x_0[:, 2]], c='b', label='y = 0') \n",
        "    plt.scatter([x_1[:, 1]], [x_1[:, 2]], c='r', label='y = 1') \n",
        "      \n",
        "    # plotting decision boundary \n",
        "    x1 = np.arange(0, 1, 0.1) \n",
        "    x2 = -(theta[0,0] + theta[0,1]*x1)/theta[0,2] \n",
        "    plt.plot(x1, x2, c='k', label='reg line') \n",
        "  \n",
        "    plt.xlabel('x1') \n",
        "    plt.ylabel('x2') \n",
        "    plt.legend() \n",
        "    plt.show() \n",
        "      \n",
        "  \n",
        "      \n",
        "if __name__ == \"__main__\": \n",
        "    # load the dataset\n",
        "\n",
        "    dataset = pd.read_csv('dataset1.csv')  \n",
        "    dataset=np.array(dataset)\n",
        "    # normalizing feature matrix \n",
        "    X = ZScore(dataset[:, :-1]) \n",
        "    # stacking columns wth all ones in feature matrix \n",
        "    X = np.hstack((np.matrix(np.ones(X.shape[0])).T, X)) \n",
        "    print(X)\n",
        "    # response vector \n",
        "    y = dataset[:, -1] \n",
        "    print (y )\n",
        "    # initial beta values \n",
        "    theta = np.matrix(np.zeros(X.shape[1])) \n",
        "    print (theta )\n",
        "    # beta values after running gradient descent \n",
        "    theta, num_iter = grad_desc(X, y, theta) \n",
        "  \n",
        "    # estimated beta values and number of iterations \n",
        "    print(\"Estimated regression coefficients:\", theta) \n",
        "    print(\"No. of iterations:\", num_iter) \n",
        "  \n",
        "    # predicted labels \n",
        "    y_pred = pred_values(theta, X) \n",
        "      \n",
        "    # number of correctly predicted labels \n",
        "    print(\"Correctly predicted labels:\", np.sum(y == y_pred)) \n",
        "      \n",
        "    # plotting regression line \n",
        "    plot_reg(X, y, theta) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.00000000e+00 -1.26676148e+00 -1.70967165e+00]\n",
            " [ 1.00000000e+00 -3.83105284e-01 -1.53496683e+00]\n",
            " [ 1.00000000e+00  3.88507676e-01 -1.25357993e+00]\n",
            " [ 1.00000000e+00  6.99651454e-01 -8.16867057e-01]\n",
            " [ 1.00000000e+00  3.88507676e-01 -8.75101998e-01]\n",
            " [ 1.00000000e+00  6.74763886e-01 -5.93665909e-01]\n",
            " [ 1.00000000e+00  9.11244962e-01 -2.83161535e-01]\n",
            " [ 1.00000000e+00  8.73913611e-01 -6.61590278e-01]\n",
            " [ 1.00000000e+00  1.54597630e+00 -1.37574184e-01]\n",
            " [ 1.00000000e+00  1.17256442e+00 -5.54859010e-01]\n",
            " [ 1.00000000e+00  1.28460766e+00 -2.05498553e-01]\n",
            " [ 1.00000000e+00  1.34682658e+00  3.47585826e-01]\n",
            " [ 1.00000000e+00  7.61870372e-01 -3.08429168e-02]\n",
            " [ 1.00000000e+00  1.64519569e-01 -5.06362683e-01]\n",
            " [ 1.00000000e+00 -2.71111231e-01 -9.81833265e-01]\n",
            " [ 1.00000000e+00 -1.00539284e+00 -1.45735303e+00]\n",
            " [ 1.00000000e+00 -1.26676148e+00 -1.84552039e+00]\n",
            " [ 1.00000000e+00 -2.02593066e+00 -1.89401671e+00]\n",
            " [ 1.00000000e+00 -1.42853067e+00 -1.61262981e+00]\n",
            " [ 1.00000000e+00 -8.56018250e-01 -1.78728545e+00]\n",
            " [ 1.00000000e+00 -4.20436635e-01 -1.69993304e+00]\n",
            " [ 1.00000000e+00 -8.44052902e-02 -1.54465626e+00]\n",
            " [ 1.00000000e+00 -8.31130683e-01 -1.09830315e+00]\n",
            " [ 1.00000000e+00  6.49201144e-02 -7.19825218e-01]\n",
            " [ 1.00000000e+00  6.12544968e-01 -4.67506600e-01]\n",
            " [ 1.00000000e+00  6.12544968e-01 -3.12279005e-01]\n",
            " [ 1.00000000e+00  1.07301415e+00 -1.70967165e+00]\n",
            " [ 1.00000000e+00  1.29705144e+00 -1.28264821e+00]\n",
            " [ 1.00000000e+00  5.50326049e-01 -1.59320177e+00]\n",
            " [ 1.00000000e+00 -2.58667447e-01 -1.77759602e+00]\n",
            " [ 1.00000000e+00 -7.19615065e-02 -1.18560637e+00]\n",
            " [ 1.00000000e+00  2.51626055e-01 -9.52715795e-01]\n",
            " [ 1.00000000e+00  4.88057946e-01 -5.35480154e-01]\n",
            " [ 1.00000000e+00  1.04812658e+00 -1.27884756e-01]\n",
            " [ 1.00000000e+00  1.32193901e+00  1.43812719e-01]\n",
            " [ 1.00000000e+00  1.62063900e+00  3.37896397e-01]\n",
            " [ 1.00000000e+00  1.72018927e+00  4.67708805e-02]\n",
            " [ 1.00000000e+00  1.83218333e+00  1.92358231e-01]\n",
            " [ 1.00000000e+00  1.39660171e+00 -5.93665909e-01]\n",
            " [ 1.00000000e+00  9.73463880e-01 -8.75101998e-01]\n",
            " [ 1.00000000e+00  2.39182271e-01 -1.04006821e+00]\n",
            " [ 1.00000000e+00 -4.70739390e-02 -1.14679947e+00]\n",
            " [ 1.00000000e+00  7.99201723e-01 -5.83976481e-01]\n",
            " [ 1.00000000e+00  1.30949523e+00 -2.34616023e-01]\n",
            " [ 1.00000000e+00  1.48370820e+00  3.76703296e-01]\n",
            " [ 1.00000000e+00  1.91933900e+00  7.55181224e-01]\n",
            " [ 1.00000000e+00  1.39660171e+00  1.14695249e-01]\n",
            " [ 1.00000000e+00  7.74314156e-01  1.05005821e-01]\n",
            " [ 1.00000000e+00  5.00501729e-01 -1.27884756e-01]\n",
            " [ 1.00000000e+00 -1.12983068e+00 -2.15237166e-01]\n",
            " [ 1.00000000e+00 -1.51563716e+00 -6.71328891e-01]\n",
            " [ 1.00000000e+00 -1.64012418e+00 -1.00126131e+00]\n",
            " [ 1.00000000e+00 -3.45773933e-01 -2.92850964e-01]\n",
            " [ 1.00000000e+00 -7.81355548e-01 -6.22783379e-01]\n",
            " [ 1.00000000e+00  2.26738488e-01  1.24433863e-01]\n",
            " [ 1.00000000e+00 -4.45324203e-01 -8.90778572e-02]\n",
            " [ 1.00000000e+00 -8.93398786e-01 -2.92850964e-01]\n",
            " [ 1.00000000e+00 -4.45324203e-01  1.82619618e-01]\n",
            " [ 1.00000000e+00  4.00325470e-02  5.22290647e-01]\n",
            " [ 1.00000000e+00 -5.95177227e-02  2.69972029e-01]\n",
            " [ 1.00000000e+00  4.63170378e-01  7.06635712e-01]\n",
            " [ 1.00000000e+00  3.63620108e-01  4.83483748e-01]\n",
            " [ 1.00000000e+00  8.24089291e-01  8.61912491e-01]\n",
            " [ 1.00000000e+00  3.51176325e-01  8.03677551e-01]\n",
            " [ 1.00000000e+00  7.86757940e-01  1.04630674e+00]\n",
            " [ 1.00000000e+00  1.07301415e+00  1.23065181e+00]\n",
            " [ 1.00000000e+00  1.07301415e+00  8.91029961e-01]\n",
            " [ 1.00000000e+00  1.75752062e+00  1.27919732e+00]\n",
            " [ 1.00000000e+00  1.34682658e+00  1.06568560e+00]\n",
            " [ 1.00000000e+00  1.34682658e+00  1.35681111e+00]\n",
            " [ 1.00000000e+00  4.00325470e-02  1.26950789e+00]\n",
            " [ 1.00000000e+00 -3.95549068e-01  7.26063754e-01]\n",
            " [ 1.00000000e+00 -7.56467981e-01  3.86441909e-01]\n",
            " [ 1.00000000e+00 -1.30409283e+00 -1.72544659e-03]\n",
            " [ 1.00000000e+00 -1.59034904e+00 -4.09320844e-01]\n",
            " [ 1.00000000e+00 -2.02593066e+00 -7.78060159e-01]\n",
            " [ 1.00000000e+00 -2.02593066e+00  3.76703296e-01]\n",
            " [ 1.00000000e+00 -1.50319337e+00  6.48449956e-01]\n",
            " [ 1.00000000e+00 -1.77700580e+00 -3.08429168e-02]\n",
            " [ 1.00000000e+00 -1.27920527e+00  9.00719390e-01]\n",
            " [ 1.00000000e+00 -1.05516797e+00  5.22290647e-01]\n",
            " [ 1.00000000e+00 -4.95099338e-01  1.05599617e+00]\n",
            " [ 1.00000000e+00 -1.71511776e-01  1.08511364e+00]\n",
            " [ 1.00000000e+00  7.73638981e-02  1.54120536e+00]\n",
            " [ 1.00000000e+00  5.87657400e-01  1.21127295e+00]\n",
            " [ 1.00000000e+00  2.14294704e-01  9.97761229e-01]\n",
            " [ 1.00000000e+00  4.75614162e-01  1.71586100e+00]\n",
            " [ 1.00000000e+00 -4.57767987e-01  1.24039042e+00]\n",
            " [ 1.00000000e+00 -1.29164905e+00  1.07542421e+00]\n",
            " [ 1.00000000e+00 -1.81433715e+00  7.45491795e-01]\n",
            " [ 1.00000000e+00 -1.61523661e+00  2.11737088e-01]\n",
            " [ 1.00000000e+00 -1.26676148e+00  4.05820766e-01]\n",
            " [ 1.00000000e+00 -9.05842570e-01 -5.99603870e-02]\n",
            " [ 1.00000000e+00 -1.71511776e-01  3.86441909e-01]\n",
            " [ 1.00000000e+00  4.75614162e-01  1.15303801e+00]\n",
            " [ 1.00000000e+00 -1.71511776e-01  6.09593873e-01]\n",
            " [ 1.00000000e+00  1.25972009e+00  1.64793663e+00]\n",
            " [ 1.00000000e+00 -1.84004745e-01  1.74497847e+00]\n",
            " [ 1.00000000e+00 -1.84004745e-01  1.54823881e+00]]\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0.]\n",
            "[[0. 0. 0.]]\n",
            "Estimated regression coefficients: [[-2.11939284  6.30889838 -9.11721944]]\n",
            "No. of iterations: 1003\n",
            "Correctly predicted labels: 99\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEGCAYAAAB7DNKzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niCgjJgoiIsqIiYKIiDJioiAiooz+P0oCg6TeAkSmAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SiL_wlcibT5",
        "colab_type": "text"
      },
      "source": [
        "###Logistic Regression using Min-Max Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bXErmewiFHm",
        "colab_type": "code",
        "outputId": "03be3900-93ab-43b2-8a7c-72da1b4183c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import csv \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import pandas as pd \n",
        "  \n",
        "def MinMax(X): \n",
        "    ''' \n",
        "    function to normalize feature matrix, X \n",
        "    '''\n",
        "    mins = np.min(X, axis = 0) \n",
        "    maxs = np.max(X, axis = 0) \n",
        "    rng = maxs - mins \n",
        "    norm_X = 1 - ((maxs - X)/rng) \n",
        "    return norm_X \n",
        "  \n",
        "  \n",
        "def ZScore(X):\n",
        "    '''\n",
        "    function to normalize feature matrix, X\n",
        "    '''\n",
        "    diff = X - np.mean(X)\n",
        "    norm_X = diff/np.std(X)\n",
        "    return norm_X\n",
        "\n",
        "\n",
        "def logistic_func(theta, X): \n",
        "    ''' \n",
        "    logistic(sigmoid) function 1/1+e^-theta.T * X\n",
        "    '''\n",
        "    return 1.0/(1 + np.exp(-np.dot(X, theta.T))) \n",
        "  \n",
        "  \n",
        "def log_gradient(theta, X, y): \n",
        "    ''' \n",
        "    logistic gradient function [Y(PREDICTION)- Y(ACTUAL)).Transpose *  X\n",
        "    '''\n",
        "    first_calc = logistic_func(theta, X) - y.reshape(X.shape[0], -1) \n",
        "    final_calc = np.dot(first_calc.T, X) \n",
        "    return final_calc \n",
        "  \n",
        "  \n",
        "def cost_func(theta, X, y): \n",
        "    ''' \n",
        "    cost function, J \n",
        "    '''\n",
        "    log_func_v = logistic_func(theta, X) \n",
        "    y = np.squeeze(y) \n",
        "    step1 = y * np.log(log_func_v) \n",
        "    step2 = (1 - y) * np.log(1 - log_func_v) \n",
        "    final = -step1 - step2 \n",
        "    return np.mean(final) \n",
        "  \n",
        "  \n",
        "def grad_desc(X, y, theta, lr=.01, converge_change=.001): \n",
        "    ''' \n",
        "    gradient descent function \n",
        "    '''\n",
        "    cost = cost_func(theta, X, y) \n",
        "    change_cost = 1\n",
        "    num_iter = 1\n",
        "      \n",
        "    while(change_cost > converge_change): \n",
        "        old_cost = cost \n",
        "        theta = theta - (lr * log_gradient(theta, X, y)) \n",
        "        cost = cost_func(theta, X, y) \n",
        "        change_cost = old_cost - cost \n",
        "        num_iter += 1\n",
        "      \n",
        "    return theta, num_iter  \n",
        "  \n",
        "  \n",
        "def pred_values(theta, X): \n",
        "    ''' \n",
        "    function to predict labels \n",
        "    '''\n",
        "    pred_prob = logistic_func(theta, X) \n",
        "    pred_value = np.where(pred_prob >= .5, 1, 0) \n",
        "    return np.squeeze(pred_value) \n",
        "  \n",
        "  \n",
        "def plot_reg(X, y, theta): \n",
        "    ''' \n",
        "    function to plot decision boundary \n",
        "    '''\n",
        "    # labelled observations \n",
        "    x_0 = X[np.where(y == 0.0)] \n",
        "    x_1 = X[np.where(y == 1.0)] \n",
        "      \n",
        "    # plotting points with diff color for diff label \n",
        "    plt.scatter([x_0[:, 1]], [x_0[:, 2]], c='b', label='y = 0') \n",
        "    plt.scatter([x_1[:, 1]], [x_1[:, 2]], c='r', label='y = 1') \n",
        "      \n",
        "    # plotting decision boundary \n",
        "    x1 = np.arange(0, 1, 0.1) \n",
        "    x2 = -(theta[0,0] + theta[0,1]*x1)/theta[0,2] \n",
        "    plt.plot(x1, x2, c='k', label='reg line') \n",
        "  \n",
        "    plt.xlabel('x1') \n",
        "    plt.ylabel('x2') \n",
        "    plt.legend() \n",
        "    plt.show() \n",
        "      \n",
        "  \n",
        "      \n",
        "if __name__ == \"__main__\": \n",
        "    # load the dataset\n",
        "\n",
        "    dataset = pd.read_csv('dataset1.csv')  \n",
        "    dataset=np.array(dataset)\n",
        "    # normalizing feature matrix \n",
        "    X = MinMax(dataset[:, :-1]) \n",
        "    # stacking columns wth all ones in feature matrix \n",
        "    X = np.hstack((np.matrix(np.ones(X.shape[0])).T, X)) \n",
        "    print(X)\n",
        "    # response vector \n",
        "    y = dataset[:, -1] \n",
        "    print (y )\n",
        "    # initial beta values \n",
        "    theta = np.matrix(np.zeros(X.shape[1])) \n",
        "    print (theta )\n",
        "    # beta values after running gradient descent \n",
        "    theta, num_iter = grad_desc(X, y, theta) \n",
        "  \n",
        "    # estimated beta values and number of iterations \n",
        "    print(\"Estimated regression coefficients:\", theta) \n",
        "    print(\"No. of iterations:\", num_iter) \n",
        "  \n",
        "    # predicted labels \n",
        "    y_pred = pred_values(theta, X) \n",
        "      \n",
        "    # number of correctly predicted labels \n",
        "    print(\"Correctly predicted labels:\", np.sum(y == y_pred)) \n",
        "      \n",
        "    # plotting regression line \n",
        "    plot_reg(X, y, theta) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.19242517 0.05065823]\n",
            " [1.         0.41640382 0.09866732]\n",
            " [1.         0.6119831  0.17599276]\n",
            " [1.         0.69084812 0.29600195]\n",
            " [1.         0.6119831  0.27999892]\n",
            " [1.         0.68453991 0.35733787]\n",
            " [1.         0.74448032 0.44266483]\n",
            " [1.         0.73501801 0.33867218]\n",
            " [1.         0.90536447 0.4826724 ]\n",
            " [1.         0.81071647 0.36800205]\n",
            " [1.         0.83911585 0.4640067 ]\n",
            " [1.         0.85488637 0.61599492]\n",
            " [1.         0.70661863 0.51200227]\n",
            " [1.         0.55520926 0.3813289 ]\n",
            " [1.         0.44479074 0.25066905]\n",
            " [1.         0.25867378 0.11999567]\n",
            " [1.         0.19242517 0.01332685]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.15142184 0.07732544]\n",
            " [1.         0.29653547 0.02932987]\n",
            " [1.         0.40694152 0.05333441]\n",
            " [1.         0.49211474 0.09600465]\n",
            " [1.         0.30284368 0.21866299]\n",
            " [1.         0.52996397 0.32266915]\n",
            " [1.         0.6687694  0.3920066 ]\n",
            " [1.         0.6687694  0.43466331]\n",
            " [1.         0.78548365 0.05065823]\n",
            " [1.         0.84226996 0.16800476]\n",
            " [1.         0.65299889 0.08266429]\n",
            " [1.         0.44794485 0.03199254]\n",
            " [1.         0.49526885 0.19467196]\n",
            " [1.         0.57728797 0.25867056]\n",
            " [1.         0.63721591 0.37332739]\n",
            " [1.         0.77917545 0.48533506]\n",
            " [1.         0.84857816 0.55999784]\n",
            " [1.         0.92428908 0.61333225]\n",
            " [1.         0.9495219  0.53333063]\n",
            " [1.         0.97790882 0.5733382 ]\n",
            " [1.         0.86750277 0.35733787]\n",
            " [1.         0.76025083 0.27999892]\n",
            " [1.         0.57413387 0.23466602]\n",
            " [1.         0.50157705 0.20533614]\n",
            " [1.         0.71608093 0.36000054]\n",
            " [1.         0.84542406 0.45600519]\n",
            " [1.         0.88958149 0.62399643]\n",
            " [1.         1.         0.7280026 ]\n",
            " [1.         0.86750277 0.55199632]\n",
            " [1.         0.70977273 0.54933366]\n",
            " [1.         0.64037001 0.48533506]\n",
            " [1.         0.22713276 0.46133052]\n",
            " [1.         0.12934312 0.335996  ]\n",
            " [1.         0.09778964 0.2453302 ]\n",
            " [1.         0.42586613 0.44000216]\n",
            " [1.         0.31546009 0.34933636]\n",
            " [1.         0.57097977 0.55467251]\n",
            " [1.         0.40063331 0.49599924]\n",
            " [1.         0.2870607  0.44000216]\n",
            " [1.         0.40063331 0.57066202]\n",
            " [1.         0.52365577 0.664004  ]\n",
            " [1.         0.49842295 0.59466656]\n",
            " [1.         0.63090771 0.71466223]\n",
            " [1.         0.60567489 0.65333982]\n",
            " [1.         0.72238914 0.75733247]\n",
            " [1.         0.60252079 0.74132944]\n",
            " [1.         0.71292683 0.80800422]\n",
            " [1.         0.78548365 0.85866245]\n",
            " [1.         0.78548365 0.76533398]\n",
            " [1.         0.9589842  0.87200281]\n",
            " [1.         0.85488637 0.81332955]\n",
            " [1.         0.85488637 0.89333117]\n",
            " [1.         0.52365577 0.86934015]\n",
            " [1.         0.41324972 0.72000108]\n",
            " [1.         0.32176829 0.62667261]\n",
            " [1.         0.18296286 0.52000378]\n",
            " [1.         0.11040604 0.40799611]\n",
            " [1.         0.         0.30666613]\n",
            " [1.         0.         0.62399643]\n",
            " [1.         0.13249723 0.69867272]\n",
            " [1.         0.06309451 0.51200227]\n",
            " [1.         0.18927107 0.76799665]\n",
            " [1.         0.24605737 0.664004  ]\n",
            " [1.         0.3880169  0.81066688]\n",
            " [1.         0.47003603 0.8186684 ]\n",
            " [1.         0.53311807 0.94400292]\n",
            " [1.         0.6624612  0.85333712]\n",
            " [1.         0.56782566 0.79466386]\n",
            " [1.         0.63406181 0.99199849]\n",
            " [1.         0.39747921 0.86133863]\n",
            " [1.         0.18611696 0.81600573]\n",
            " [1.         0.0536322  0.72533993]\n",
            " [1.         0.10409784 0.57866353]\n",
            " [1.         0.19242517 0.63199795]\n",
            " [1.         0.2839066  0.50400076]\n",
            " [1.         0.47003603 0.62667261]\n",
            " [1.         0.63406181 0.83733409]\n",
            " [1.         0.47003603 0.68799503]\n",
            " [1.         0.83280765 0.97333279]\n",
            " [1.         0.46686946 1.        ]\n",
            " [1.         0.46686946 0.94593572]]\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0.]\n",
            "[[0. 0. 0.]]\n",
            "Estimated regression coefficients: [[  1.6908351   15.00842207 -20.4138904 ]]\n",
            "No. of iterations: 2613\n",
            "Correctly predicted labels: 99\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}